import streamlit as st
# ğŸš¨ ìºì‹œ ì™„ì „ ì´ˆê¸°í™”
st.cache_resource.clear()

# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import os, sys, io, re, joblib, tempfile, json, datetime, traceback, shap, importlib
import matplotlib
matplotlib.rc('font', family='Malgun Gothic')
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.lib.utils import ImageReader
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ======================
# ğŸ”¹ Google Drive ì„¤ì •
# ======================
FOLDER_ID = '1rTMoyzj1qxc8ET5648XvF0E-3oN46lel'

# ======================
# ğŸ”¹ Google Sheets ì„¤ì •
# ======================
SPREADSHEET_ID = '17Y24_hFUJSXXTdHVbL6doo6A2pnvmsRDCG98Ihvenlw'

@st.cache_resource
def get_sheets_client():
    """Google Sheets í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    try:
        if 'google' in st.secrets:
            service_account_info = dict(st.secrets['google'])
        else:
            st.error("Google Sheets ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        scope = [
            'https://spreadsheets.google.com/feeds',
            'https://www.googleapis.com/auth/drive'
        ]
        credentials = ServiceAccountCredentials.from_json_keyfile_dict(
            service_account_info, scope
        )
        client = gspread.authorize(credentials)
        return client
    except Exception as e:
        st.error(f"Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None

def save_to_sheets(user_data):
    """ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ë¥¼ Google Sheetsì— ì €ì¥"""
    try:
        client = get_sheets_client()
        if not client:
            return False
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
        sheet = client.open_by_key(SPREADSHEET_ID).sheet1
        
        # ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í—¤ë” ìˆœì„œì™€ ë™ì¼í•˜ê²Œ)
        row_data = [
            user_data.get('timestamp', ''),
            user_data.get('language', ''),
            user_data.get('hospital', ''),
            user_data.get('id', ''),
            user_data.get('birth', ''),
            user_data.get('sex', ''),
            user_data.get('name', ''),
            user_data.get('hsptcd', ''),
            user_data.get('side', ''),
            user_data.get('hl_duration', ''),
            user_data.get('clinic_date', ''),
            user_data.get('steroid_treatment', ''),
            user_data.get('it_dexa_treatment', ''),
            user_data.get('hyperbaric_treatment', ''),
            user_data.get('pta_rt_ac_250', ''),
            user_data.get('pta_rt_ac_500', ''),
            user_data.get('pta_rt_ac_1000', ''),
            user_data.get('pta_rt_ac_2000', ''),
            user_data.get('pta_rt_ac_3000', ''),
            user_data.get('pta_rt_ac_4000', ''),
            user_data.get('pta_rt_ac_8000', ''),
            user_data.get('pta_lt_ac_250', ''),
            user_data.get('pta_lt_ac_500', ''),
            user_data.get('pta_lt_ac_1000', ''),
            user_data.get('pta_lt_ac_2000', ''),
            user_data.get('pta_lt_ac_3000', ''),
            user_data.get('pta_lt_ac_4000', ''),
            user_data.get('pta_lt_ac_8000', ''),
            user_data.get('wbc', ''),
            user_data.get('rbc', ''),
            user_data.get('hb', ''),
            user_data.get('plt', ''),
            user_data.get('neutrophil', ''),
            user_data.get('lymphocyte', ''),
            user_data.get('ast', ''),
            user_data.get('alt', ''),
            user_data.get('bun', ''),
            user_data.get('cr', ''),
            user_data.get('glucose', ''),
            user_data.get('total_protein', ''),
            user_data.get('na', ''),
            user_data.get('k', ''),
            user_data.get('cl', ''),
            user_data.get('dx_com', ''),
            user_data.get('dx_ssnhl', ''),
            user_data.get('dx_dizziness', ''),
            user_data.get('dx_tinnitus', ''),
            user_data.get('hx_htn', ''),
            user_data.get('hx_dm', ''),
            user_data.get('hx_crf', ''),
            user_data.get('hx_mi', ''),
            user_data.get('hx_stroke', ''),
            user_data.get('hx_cancer', ''),
            user_data.get('hx_others', ''),
            user_data.get('prediction', ''),
            user_data.get('probability', '')
        ]
        
        # ì‹œíŠ¸ì— í–‰ ì¶”ê°€
        sheet.append_row(row_data)
        return True
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        return False

@st.cache_resource
def get_drive_service():
    """Google Drive ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±"""
    try:
        if 'google' in st.secrets:
            service_account_info = st.secrets['google']
        else:
            st.error("Google Drive ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        credentials = service_account.Credentials.from_service_account_info(
            service_account_info,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        return build('drive', 'v3', credentials=credentials)
    except Exception as e:
        st.error(f"Google Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None

@st.cache_data
def download_file_from_drive(file_name):
    """Google Driveì—ì„œ ì§€ì •ëœ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ (predictors, models í´ë” í¬í•¨)"""
    service = get_drive_service()
    if not service:
        return None

    def find_file_recursive(folder_id, target_name):
        """í´ë” ì „ì²´ë¥¼ ì¬ê·€ íƒìƒ‰ (predictors/, models/ ëª¨ë‘ ì§€ì›)"""
        try:
            # í˜„ì¬ í´ë”ì—ì„œ íŒŒì¼ ê²€ìƒ‰
            query = f"'{folder_id}' in parents and name='{target_name}' and trashed=false"
            results = service.files().list(q=query, fields="files(id, name, mimeType)").execute()
            files = results.get("files", [])
            if files:
                return files[0]["id"]

            # í•˜ìœ„ í´ë” ê²€ìƒ‰
            subfolders_query = f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
            subfolders = service.files().list(q=subfolders_query, fields="files(id, name)").execute().get("files", [])

            for sub in subfolders:
                found = find_file_recursive(sub["id"], target_name)
                if found:
                    return found

            return None
        except Exception as e:
            st.warning(f"í´ë” íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({target_name}): {e}")
            return None

    # ğŸ” ì‹¤ì œ íƒìƒ‰ ì‹œì‘
    file_id = find_file_recursive(FOLDER_ID, os.path.basename(file_name))

    if not file_id:
        st.warning(f"âŒ Google Driveì—ì„œ {file_name}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    try:
        request = service.files().get_media(fileId=file_id)
        file_data = io.BytesIO()
        downloader = MediaIoBaseDownload(file_data, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()
        file_data.seek(0)
        return file_data
    except Exception as e:
        st.error(f"ğŸ“ {file_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None


# ======================
# ğŸ”¹ predictor ëª¨ë“ˆ ë¡œë“œ
# ======================
@st.cache_resource
def load_predictor_modules():
    predictor_files = [
        'predictors/all.py', 'predictors/wonju.py', 'predictors/sev.py',
        'predictors/hallym.py', 'predictors/jeju.py', 'predictors/hagen.py'
    ]
    temp_dir = tempfile.mkdtemp()
    predictors_dir = os.path.join(temp_dir, 'predictors')
    os.makedirs(predictors_dir, exist_ok=True)

    with open(os.path.join(predictors_dir, '__init__.py'), 'w') as f:
        f.write('')

    for file_path in predictor_files:
        content = download_file_from_drive(file_path)
        if content:
            with open(os.path.join(predictors_dir, os.path.basename(file_path)), 'wb') as f:
                f.write(content.read())
        else:
            st.warning(f"âš ï¸ {file_path} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

    if 'predictors' in sys.modules:
        del sys.modules['predictors']

    sys.path = [p for p in sys.path if 'predictors' not in p]
    parent_dir = os.path.dirname(predictors_dir)
    sys.path.insert(0, parent_dir)
    sys.path.insert(0, predictors_dir)

    return predictors_dir

# ======================
# ğŸ”¹ preprocessing / translation
# ======================
@st.cache_resource
def load_preprocessing_and_translation():
    files = ['preprocessing.py', 'translate_texts.py']
    temp_dir = tempfile.mkdtemp()
    if temp_dir not in sys.path:
        sys.path.insert(0, temp_dir)

    for f in files:
        content = download_file_from_drive(f)
        if content:
            with open(os.path.join(temp_dir, f), 'wb') as w:
                w.write(content.read())

    try:
        from preprocessing import load_and_process_data, impute_data, finalize_data
        from translate_texts import texts_ko, texts_en_us, texts_ja, texts_zh, texts_es, texts_de, texts_hi, texts_ar
        return True
    except Exception as e:
        st.error(f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False

# ======================
# ğŸ”¹ ëª¨ë¸ íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
# ======================
@st.cache_resource
def load_models_from_drive():
    """Google Driveì—ì„œ ëª¨ë¸ íŒŒì¼ ë¡œë“œ"""
    model_files = {
        "all": {
            "lgbm": "models/all_lightgbm_model.joblib",
            "xgb": "models/all_xgboost_model.joblib",
            "scaler": "models/all_minmax_scaler.joblib"
        },
        "wonju": {
            "lgbm": "models/ys_lightgbm_model.joblib",
            "xgb": "models/ys_xgboost_model.joblib",
            "scaler": "models/ys_minmax_scaler.joblib"
        },
        "sev": {
            "lgbm": "models/sev_lightgbm_model.joblib",
            "xgb": "models/sev_xgboost_model.joblib",
            "scaler": "models/sev_minmax_scaler.joblib"
        },
        "hallym": {
            "lgbm": "models/hallym_lightgbm_model.joblib",
            "xgb": "models/hallym_xgboost_model.joblib",
            "scaler": "models/hallym_minmax_scaler.joblib"
        },
        "jeju": {
            "lgbm": "models/jeju_lightgbm_model.joblib",
            "xgb": "models/jeju_xgboost_model.joblib",
            "scaler": "models/jeju_minmax_scaler.joblib"
        },
        "hagen": {
            "lgbm": "models/hagen_lightgbm_model.joblib",
            "xgb": "models/hagen_xgboost_model.joblib",
            "scaler": "models/hagen_minmax_scaler.joblib"
        }
    }

    loaded_models = {}

    for hospital, paths in model_files.items():
        loaded_models[hospital] = {}
        for model_type, path in paths.items():
            try:
                content = download_file_from_drive(path)
                if content:
                    tmp = tempfile.NamedTemporaryFile(delete=False)
                    tmp.write(content.read())
                    tmp.close()
                    loaded_models[hospital][model_type] = joblib.load(tmp.name)
                else:
                    st.warning(f"âš ï¸ {hospital} {model_type} ëª¨ë¸ ì—†ìŒ")
            except Exception as e:
                st.error(f"âŒ {hospital} {model_type} ë¡œë“œ ì‹¤íŒ¨: {e}")

    return loaded_models

# ======================
# ğŸ”¹ ë©”ì¸ ì‹¤í–‰ (íŒŒì¼ ë¡œë“œ)
# ======================
with st.spinner("Google Driveì—ì„œ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
    modules_loaded = load_preprocessing_and_translation()
    if not modules_loaded:
        st.error("í•„ìˆ˜ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨")
        st.stop()

    predictor_dir = load_predictor_modules()

    # âœ… predictors import (ê°•ì œ ìºì‹œ ì´ˆê¸°í™” + ë””ë²„ê·¸)
    if 'predictors' in sys.modules:
        del sys.modules['predictors']
    sys.path.insert(0, predictor_dir)

    try:
        predictors_all = importlib.import_module("predictors.all")
    except ModuleNotFoundError as e:
        st.warning(f"âš ï¸ Predictor ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        predictors_all = None

    # âœ… ëª¨ë¸ ë¡œë“œ
    models = load_models_from_drive()

# ì´í›„ì˜ UI / ì˜ˆì¸¡ íŒŒíŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€


# ì´ì œ import ê°€ëŠ¥
from preprocessing import load_and_process_data, impute_data, finalize_data
from translate_texts import texts_ko, texts_en_us, texts_ja, texts_zh, texts_es, texts_de, texts_hi, texts_ar

# ==== ë©”ì¸ UI ë””ìì¸
st.markdown("""
<style>
/* ===== 1. ë©”ì¸ ì œëª© ìŠ¤íƒ€ì¼ ===== */
.main-title {
    text-align: center;
    font-size: 4em;
    color: #0077B6;
    font-weight: 700;
    margin-bottom: 0.5em;
    white-space: nowrap;
}

/* ===== 2. ë³¸ë¬¸ ìµœëŒ€ í­ ë„“íˆê¸° ===== */
.block-container {
    max-width: 1200px;
    padding-left: 5rem;
    padding-right: 5rem;
}

/* ===== 3. ì˜ˆì¸¡ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ===== */
div.stButton > button:first-child {
    background-color: #0077B6;
    color: white;
    font-size: 18px;
    padding: 0.6em 1.2em;
    border-radius: 6px;
}

/* ===== 4. ì‚¬ì´ë“œë°” ì´ë¯¸ì§€ ì—¬ë°± ì œê±° ===== */
[data-testid="stSidebar"] img {
    margin-top: 0px;
}

/* ===== 5. ì‚¬ì´ë“œë°” ì „ì²´ ìœ„ ì—¬ë°± ì œê±° ===== */
[data-testid="stSidebar"] .block-container {
    padding-top: 1rem;
    padding-left: 1rem;
    padding-right: 1rem;
}
[data-testid="stSidebar"] {
    overflow-x: hidden;
}
            
            
</style>

<!-- ë©”ì¸ ì œëª© -->
<div class="main-title">Prediction Model for Prognosis of SSNHL</div>
""", unsafe_allow_html=True)

# ===== ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(__file__) if '__file__' in globals() else os.getcwd()
sys.path.append(BASE_DIR)

lang_options = {
    "í•œêµ­ì–´": "ko",
    "English": "en-us",
    "æ—¥æœ¬èª" : "ja",
    "ä¸­æ–‡": "zh",
    "EspaÃ±ol": "es",
    "Deutsch": "de",
    "à¤¹à¤¿à¤¨à¥à¤¦à¥€": "hi",
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ar",
}

with st.sidebar:
    # ğŸŒ ì–¸ì–´ ì„ íƒ (ì‚¬ì´ë“œë°” ìµœìƒë‹¨)
    lang_choice_label = st.sidebar.selectbox("ğŸŒ Translate", list(lang_options.keys()), index=0)
    lang_code = lang_options[lang_choice_label]

    # ì–¸ì–´ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì‚¬ì „ ì„ íƒ
    if lang_code == "ko":
        texts = texts_ko
    elif lang_code == "en-us":
        texts = texts_en_us
    elif lang_code == "ja":
        texts = texts_ja
    elif lang_code == "zh":
        texts = texts_zh
    elif lang_code == "es":
        texts = texts_es
    elif lang_code == "de":
        texts = texts_de
    elif lang_code == "hi":
        texts = texts_hi
    elif lang_code == "ar":
        texts = texts_ar
    else:
        texts = texts_ko  # ê¸°ë³¸ê°’

    # ë¡œê³  - Google Driveì—ì„œ ë¡œë“œ
    logo_content = download_file_from_drive("ON AIR.jpg")
    if logo_content:
        st.image(logo_content, use_column_width=True)

# ===== ë³‘ì› ì„ íƒ
hospital_modules = {
    texts["ì „ì²´ ë³‘ì›"]: "predictors.all",
    texts["ì›ì£¼ì„¸ë¸Œë€ìŠ¤ê¸°ë…ë³‘ì›"]: "predictors.wonju",
    texts["ì‹ ì´Œ-ê°•ë‚¨ì„¸ë¸Œë€ìŠ¤ë³‘ì›"]: "predictors.sev",
    texts["í•œë¦¼ëŒ€í•™êµ ê°•ë‚¨ì„±ì‹¬ë³‘ì›"]: "predictors.hallym",
    texts["ì œì£¼ëŒ€í•™ë³‘ì›"]: "predictors.jeju",
    texts["ë…ì¼í•˜ê²ë³‘ì›"]: "predictors.hagen",
}

st.sidebar.title(f"ğŸ“‹ {texts['ë³‘ì› ì„ íƒ']}")
selected_hospital = st.sidebar.selectbox("", list(hospital_modules.keys()))

# predictor ëª¨ë“ˆ import ë° ëª¨ë¸ ì„¤ì •
try:
    predictor = importlib.import_module(hospital_modules[selected_hospital]).get_predictor()
    
    # í•´ë‹¹ ë³‘ì›ì˜ ëª¨ë¸ ì„¤ì •
    hospital_key = hospital_modules[selected_hospital].split('.')[-1]
    if hospital_key in models and 'lgbm' in models[hospital_key] and 'xgb' in models[hospital_key]:
        predictor.lgbm_model = models[hospital_key]['lgbm']
        predictor.xgb_model = models[hospital_key]['xgb']
except Exception as e:
    st.error(f"Predictor ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    st.stop()

# ì…ë ¥ê°’ ìˆ˜ì§‘
pta_values = {}
pta_frequencies = ["250", "500", "1000", "2000", "3000", "4000", "8000"]

with st.sidebar:
    with st.expander(f"ğŸ§ {texts['ê¸°ë³¸ ì •ë³´ ì…ë ¥']}"):
        id_value = st.text_input("ID")
        birth_date = st.date_input(
            texts["ìƒë…„ì›”ì¼"],
            min_value=datetime.date(1900, 1, 1),
            max_value=datetime.date.today()
        )
        gender = st.selectbox(texts["ì„±ë³„"], ["Male", "Female"])
        name = st.text_input(texts["ì´ë¦„"])
        hsptcd = st.text_input(texts["ë³‘ì›ì½”ë“œ (HSPTCD)"])

    with st.expander(f"ğŸ§  {texts['PTA ê²€ì‚¬']}"):
        for freq in pta_frequencies:
            rt = st.text_input(f"PTA_RT_AC_ {freq}", key=f"rt_{freq}")
            lt = st.text_input(f"PTA_LT_AC_ {freq}", key=f"lt_{freq}")
            pta_values[f"PTA_RT_AC_{freq}"] = float(rt) if rt.strip() else None
            pta_values[f"PTA_LT_AC_{freq}"] = float(lt) if lt.strip() else None

    with st.expander(f"ğŸ§¬ {texts['ì˜ë£Œ ì •ë³´']}"):
        side = st.selectbox(texts["ì¸¡ë©´ (Side)"], ["Right", "Left"])
        hl_duration = st.text_input(texts["HL_duration (ì¼)"])
        clinic_date = st.date_input("Clinic_date")
        steroid = st.checkbox(texts["ìŠ¤í…Œë¡œì´ë“œ ì¹˜ë£Œ"])
        it_dexa = st.checkbox(texts["IT_dexa ì¹˜ë£Œ"])
        hbot = st.checkbox(texts["ê³ ì••ì‚°ì†Œ ì¹˜ë£Œ"])

    with st.expander(f"ğŸ§ª {texts['í˜ˆì•¡ ê²€ì‚¬']}"):
        blood_tests = ["WBC", "RBC", "Hb", "PLT", "Neutrophil", "Lymphocyte",
                       "AST", "ALT", "BUN", "Cr", "Glucose", "Total_Protein",
                       "Na", "K", "Cl"]
        blood_values = {}
        for test in blood_tests:
            val = st.text_input(test)
            blood_values[test] = float(val) if val.strip() != "" else None

    with st.expander(f"ğŸ“„ {texts['ì§„ë‹¨ ë° ë³‘ë ¥']}"):
        diagnosis = ["Dx_COM", "Dx_SSNHL", "Dx_Dizziness", "Dx_Tinnitus"]
        diagnosis_values = {dx: int(st.checkbox(f"{dx} {texts['ì—¬ë¶€']}" )) for dx in diagnosis}

        history = ["Hx_HTN", "Hx_DM", "Hx_CRF", "Hx_MI", "Hx_stroke", "Hx_cancer"]
        history_values = {hx: int(st.checkbox(f"{hx} {texts['ì—¬ë¶€']}")) for hx in history}

        hx_others_text = st.text_input(f"{texts['ê¸°íƒ€ ë³‘ë ¥']} (Hx_others)")
        hx_others = 1 if hx_others_text.strip() != "" else 0

    predict_button = st.button(f"\U0001F50D {texts['ì˜ˆì¸¡ ê²°ê³¼ ë³´ê¸°']}")

# ë§¤í•‘
side_mapping = {"Right": 1, "Left": 2}
sex_mapping = {"Male": 1, "Female": 2}

def create_combined_image(result_df, shap_fig, title="ëª¨ë¸ ê²°ê³¼ ìš”ì•½", summary_text=None):
    
    fig = plt.figure(figsize=(10, 12))

    ax1 = fig.add_axes([0,0.6,1,0.35]) # [left, bottom, width, height]
    ax1.axis('off')
    ax1.set_title(title, fontsize=30, fontweight='bold', pad=30)

    table_data = [result_df.columns.tolist()] + result_df.values.tolist()
    table = Table(ax1, bbox=[0.2, 0.25, 0.6, 0.6])
    n_cols = len(table_data[0])
    for i, row in enumerate(table_data):
        for j, val in enumerate(row):
            cell = table.add_cell(i, j, width=1.0 / n_cols, height=0.25,
                           text=str(val), loc='center',
                           facecolor='#cce5ff' if i == 0 else 'white')
            cell.get_text().set_fontsize(16)
    ax1.add_table(table)

     # ì¤‘ë‹¨: í…ìŠ¤íŠ¸ ì„¤ëª… ë„£ê¸°
    if summary_text:
        ax_text = fig.add_axes([0, 0.52, 1, 0.25])
        ax_text.axis('off')
        ax_text.text(0.5, 0.5, summary_text, fontsize=15, ha='center', va='center', wrap=True)

    shap_buf = io.BytesIO()
    shap_fig.savefig(shap_buf, format='png', bbox_inches='tight')
    shap_buf.seek(0)
    shap_img = plt.imread(shap_buf)

    ax2 = fig.add_axes([0, 0, 1, 0.6])
    ax2.imshow(shap_img)
    ax2.axis('off')

    return fig

# ì˜ˆì¸¡ ë²„íŠ¼
if predict_button:
    with st.spinner(f"â³ {texts['ì˜ˆì¸¡ ì§„í–‰ ì¤‘...']}"):
        df_input = pd.DataFrame([{
            "ID": id_value,
            "Birth": birth_date.strftime("%Y-%m-%d"),
            "test_date": clinic_date.strftime("%Y-%m-%d"),
            "Sex": sex_mapping.get(gender, 1),
            "Side": side_mapping.get(side, 1),
            "HL_duration": float(hl_duration) if hl_duration.strip() else None,
            "Steroid": int(steroid),
            "IT_dexa": int(it_dexa),
            "HBOT": int(hbot),
            **pta_values,
            **blood_values,
            **diagnosis_values,
            **history_values,
            "Hx_others": hx_others
        }])

        lgbm_result, lgbm_prob, xgb_result, xgb_prob, df_lgbm, df_xgb, df_ids, lgbm_model, xgb_model, lgbm_acc, xgb_acc = predictor.predict_outcome(df_input)

        if all(v is not None for v in [lgbm_result, lgbm_prob, xgb_result, xgb_prob]):            

            # ì •í™•ë„ ê°€ì ¸ì˜¤ê¸° - Google Driveì—ì„œ txt íŒŒì¼ ë¡œë“œ
            def get_accuracy_from_drive(hospital_key, model_type):
                """Google Driveì—ì„œ ì •í™•ë„ txt íŒŒì¼ ë¡œë“œ"""
                try:
                    file_name = f"txt/{hospital_key}_{model_type}_accuracy.txt"
                    file_content = download_file_from_drive(file_name)
                    if file_content:
                        content = file_content.read().decode('utf-8')
                        # ì •í™•ë„ ê°’ ì¶”ì¶œ (ì˜ˆ: "0.8523" í˜•íƒœì˜ ìˆ«ì)
                        import re
                        numbers = re.findall(r"\d+\.\d+", content)
                        if numbers:
                            return float(numbers[0])
                    return 0.75  # ê¸°ë³¸ê°’
                except Exception as e:
                    return 0.75  # ê¸°ë³¸ê°’

            # ë³‘ì› í‚¤ ê°€ì ¸ì˜¤ê¸°
            hospital_key = hospital_modules[selected_hospital].split('.')[-1]
            
            # ì •í™•ë„ ê°’ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì²˜ë¦¬)
            if not hasattr(predictor, 'lgbm_acc') or predictor.lgbm_acc is None:
                predictor.lgbm_acc = get_accuracy_from_drive(hospital_key, 'lgbm')
            if not hasattr(predictor, 'xgb_acc') or predictor.xgb_acc is None:
                predictor.xgb_acc = get_accuracy_from_drive(hospital_key, 'xgb')

            # LightGBM ê²°ê³¼
            result_df_lgbm = pd.DataFrame({
                "ID": df_ids["ID"].values,
                "LightGBM íšŒë³µ íŒë‹¨": ["íšŒë³µ" if p >= 0.5 else "ë¹„íšŒë³µ" for p in lgbm_prob],
                "LightGBM íšŒë³µ í™•ë¥ ": [f"{(p * 100):.1f}%" for p in lgbm_prob],
                "ì˜ˆì¸¡ ì •í™•ë„": [f"{predictor.lgbm_acc * 100:.1f}%" for _ in lgbm_result]
            })

            # XGBoost ê²°ê³¼
            result_df_xgb = pd.DataFrame({
                "ID": df_ids["ID"].values,
                "XGBoost íšŒë³µ íŒë‹¨": ["íšŒë³µ" if p >= 0.5 else "ë¹„íšŒë³µ" for p in xgb_prob],
                "XGBoost íšŒë³µ í™•ë¥ ": [f"{(p * 100):.1f}%" for p in xgb_prob],
                "ì˜ˆì¸¡ ì •í™•ë„": [f"{predictor.xgb_acc * 100:.1f}%" for _ in xgb_result]
            })

            st.markdown(f"### ğŸ“‹ {texts['summary_title']}")
        
            # LightGBM íšŒë³µ í™•ë¥  (ì²« ë²ˆì§¸ ìƒ˜í”Œ ê¸°ì¤€)
            lgbm_prob_val = lgbm_prob[0] * 100
            xgb_prob_val = xgb_prob[0] * 100

            # í†µí•© ì˜ˆì¸¡ ìš”ì•½ í…Œì´ë¸” (í‘œ ìŠ¤íƒ€ì¼ë¡œ)
            
            st.markdown(f"""
            <style>
            .result-table {{
                width: 100%;
                border-collapse: collapse;
                margin-bottom: 1rem;
            }}
            .result-table th, .result-table td {{
                border: 1px solid #ccc;
                padding: 0.6rem 1rem;
                text-align: center;
                font-size: 1.05rem;
            }}
            .result-comment {{
                font-size: 1.1rem;
                line-height: 1.6;
                background-color: #e7f5ff;
                border-radius: 10px;
                padding: 1.2rem;
                border-left: 5px solid #0077B6;
                margin-bottom: 2rem;
            }}
            </style>

            <table class="result-table">
                <tr>
                    <th>{texts["ëª¨ë¸"]}</th>
                    <th>{texts["íšŒë³µ íŒë‹¨"]}</th>
                    <th>{texts["íšŒë³µ í™•ë¥ "]}</th>
                    <th>{texts["ì˜ˆì¸¡ ì •í™•ë„"]}</th>
                </tr>
                <tr>
                    <td><b>LightGBM</b></td>
                    <td style="color: {'green' if lgbm_prob[0] >= 0.5 else 'red'}; font-weight: bold;">
                        {texts['íšŒë³µ'] if lgbm_prob[0] >= 0.5 else texts['ë¹„íšŒë³µ']}
                    </td>
                    <td><b>{lgbm_prob[0]*100:.1f}%</b></td>
                    <td>{predictor.lgbm_acc*100:.1f}%</td>
                </tr>
                <tr>
                    <td><b>XGBoost</b></td>
                    <td style="color: {'green' if xgb_prob[0] >= 0.5 else 'red'}; font-weight: bold;">
                        {texts['íšŒë³µ'] if xgb_prob[0] >= 0.5 else texts['ë¹„íšŒë³µ']}
                    </td>
                    <td><b>{xgb_prob[0]*100:.1f}%</b></td>
                    <td>{predictor.xgb_acc*100:.1f}%</td>
                </tr>
            </table>

            <div class="result-comment">
                <b>{name}</b>&nbsp;{texts["ë‹˜ì˜ ì˜ˆì¸¡ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]}<br><br>
                ğŸ”µ <b>LightGBM</b> {texts["ê¸°ì¤€"]} : {texts["íšŒë³µ í™•ë¥ "]} <b>{lgbm_prob[0]*100:.1f}%</b>, 
                 {texts["ì˜ˆì¸¡ ì •í™•ë„"]} <b>{predictor.lgbm_acc*100:.1f}%<br></b>
                ğŸŸ¢ <b>XGBoost</b> {texts["ê¸°ì¤€"]} : {texts["íšŒë³µ í™•ë¥ "]} <b>{xgb_prob[0]*100:.1f}%</b>, 
                 {texts["ì˜ˆì¸¡ ì •í™•ë„"]} <b>{predictor.xgb_acc*100:.1f}%<br></b>
            </div>
            """, unsafe_allow_html=True)
      
            # ğŸ¯ SHAP explainer ë° ê³„ì‚°
            explainer_lgbm = shap.TreeExplainer(predictor.lgbm_model)
            shap_values_lgbm_raw = explainer_lgbm.shap_values(df_lgbm)  # ì›ë³¸ ì €ì¥

            explainer_xgb = shap.TreeExplainer(predictor.xgb_model)
            shap_values_xgb_raw = explainer_xgb.shap_values(df_xgb)

            # âš ï¸ multiclass ëŒ€ì‘ (ë³´í†µ binaryì´ë©´ listë¡œ ë°˜í™˜ë¨)
            shap_values_lgbm = shap_values_lgbm_raw[1] if isinstance(shap_values_lgbm_raw, list) else shap_values_lgbm_raw
            shap_values_xgb = shap_values_xgb_raw[1] if isinstance(shap_values_xgb_raw, list) else shap_values_xgb_raw
            
            target_features = [
                "WBC", "RBC", "Hb", "PLT", "Neutrophil", "Lymphocyte",
                "AST", "ALT", "BUN", "Cr", "Glucose", "Total_Protein",
                "Na", "K", "Cl"
            ]

            # âœ… ìƒí™”í•™ ë³€ìˆ˜ ì¤‘ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
            filtered_features_lgbm = [f for f in target_features if f in df_lgbm.columns]
            filtered_features_xgb = [f for f in target_features if f in df_xgb.columns]

            # âœ… í•´ë‹¹ feature ì¸ë±ìŠ¤ ì¶”ì¶œ
            feature_indices_lgbm = [df_lgbm.columns.get_loc(col) for col in filtered_features_lgbm]
            feature_indices_xgb = [df_xgb.columns.get_loc(col) for col in filtered_features_xgb]

            st.markdown(f"### {texts['ë³€ìˆ˜ ì¤‘ìš”ë„']}")

            # ì „ì²´ ë³€ìˆ˜ ì¤‘ìš”ë„ ë³´ê¸°
            with st.expander(f"ğŸ“Š {texts['ì „ì²´ ë³€ìˆ˜ ì¤‘ìš”ë„ ë³´ê¸°']}"):
                col1, col2 = st.columns(2)
                with col1:
                    fig_lgbm = plt.figure()
                    st.subheader(f"ğŸ” LightGBM {texts['ë³€ìˆ˜ ì¤‘ìš”ë„']}")
                    shap.summary_plot(shap_values_lgbm, df_lgbm, plot_type='bar', show=False)
                    plt.gcf().subplots_adjust(top=0.88)
                    st.pyplot(plt.gcf())

                with col2:
                    st.subheader(f"ğŸ” XGBoost {texts['ë³€ìˆ˜ ì¤‘ìš”ë„']}")
                    fig_xgb = plt.figure()
                    shap.summary_plot(shap_values_xgb, df_xgb, plot_type="bar", show=False)
                    plt.gcf().subplots_adjust(top=0.88)
                    st.pyplot(plt.gcf())

            normal_ranges = {
                "WBC": (4.0, 10.0), "RBC": (3.8, 5.2), "Hb": (12.0, 16.0), "PLT": (165, 360),
                "Neutrophil": (35, 75), "Lymphocyte": (25, 40), "AST": (0, 35), "ALT": (0, 40),
                "BUN": (5, 19), "Cr": (0.20, 1.10), "Glucose": (70, 110), "Total_Protein": (6.4, 8.3),
                "Na": (136, 145), "K": (3.5, 5.1), "Cl": (98, 107)
            }
            
            def plot_shap_dot_with_ranges(features, shap_values, feature_values, normal_ranges, title="SHAP Dot Plot"):
                import matplotlib.pyplot as plt
                import numpy as np

                sorted_idx = np.argsort(shap_values)[::-1]
                features_sorted = [features[i] for i in sorted_idx if features[i]]
                shap_sorted = shap_values[sorted_idx]

                fig, ax = plt.subplots(figsize=(6, 6))
                y = np.arange(len(features_sorted))

                normal_range_plotted = False
                patient_point_plotted = False

                # ì •ìƒë²”ìœ„ ë°•ìŠ¤: ì •í™•í•œ y ìœ„ì¹˜ë¡œ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                for i, feat in enumerate(features_sorted):
                    if feat in normal_ranges:
                        low, high = normal_ranges[feat]
                        width = high - low
                        label = texts["ì •ìƒë²”ìœ„"] if not normal_range_plotted else ""
                        ax.barh(i, width, left=low, height=0.6, color='green', alpha=0.2, label=label)
                        normal_range_plotted = True

                    if feat in feature_values:
                        label = texts["í™˜ììˆ˜ì¹˜"] if not patient_point_plotted else ""
                        ax.scatter(feature_values[feat], i, color='red', marker='.', label=label)
                        patient_point_plotted = True

                ax.set_yticks(y)
                ax.set_yticklabels(features_sorted)
                ax.set_xlabel(texts["ìˆ˜ì¹˜"])
                ax.set_title(title)
                ax.invert_yaxis()
                ax.legend(loc="lower right")
                plt.tight_layout()
                return fig
                        
            def plot_single_variable_graph(
                feature,
                value,
                normal_ranges,
                xlim_range=(0, 400),
                title_fontsize=9,
                tick_fontsize=8
            ):
                import matplotlib.pyplot as plt

                fig, ax = plt.subplots(figsize=(4.5, 1.0))  # ì ë‹¹íˆ ì‘ê²Œ
                ax.set_xlim(*xlim_range)
                ax.set_yticks([])
                ax.set_title(feature, fontsize=title_fontsize, pad=2)
                ax.set_xlabel(texts["ìˆ˜ì¹˜"], fontsize=tick_fontsize)

                if feature in normal_ranges:
                    low, high = normal_ranges[feature]
                    width = high - low
                    ax.barh(0, width, left=low, height=0.3, color='green', alpha=0.2, label="ì •ìƒë²”ìœ„")

                if value is not None:
                    ax.scatter(value, 0, color='red', s=25, label="í™˜ì ìˆ˜ì¹˜")

                ax.set_frame_on(False)
                ax.tick_params(axis='x', labelsize=tick_fontsize)
                plt.tight_layout()
                return fig

            # ì¡°ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ë³´ê¸°
            with st.expander(f"ğŸ› ï¸ {texts['ì¡°ì •ê°€ëŠ¥í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ë³´ê¸°']}"):
                col3, col4 = st.columns(2)
                with col3:
                    st.subheader(f"ğŸ§ª LightGBM {texts['ì¡°ì •ê°€ëŠ¥ ë³€ìˆ˜']}")
                    plt.clf()
                    shap.summary_plot(
                        shap_values_lgbm[:, feature_indices_lgbm],
                        df_lgbm[filtered_features_lgbm],
                        plot_type="bar", show=False
                    )
                    plt.gcf().subplots_adjust(top=0.90)
                    st.pyplot(plt.gcf())

                with col4:
                    st.subheader(f"ğŸ§ª XGBoost {texts['ì¡°ì •ê°€ëŠ¥ ë³€ìˆ˜']}")
                    shap.summary_plot(
                        shap_values_xgb[:, feature_indices_xgb],
                        df_xgb[filtered_features_xgb],
                        plot_type="bar", show=False
                    )
                    plt.gcf().subplots_adjust(top=0.90)
                    st.pyplot(plt.gcf())

            # ë³€ìˆ˜ë³„ xì¶• ë²”ìœ„ ì„¤ì • (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            custom_xlims = {
                "WBC": (0, 20), "RBC": (0, 8), "Hb": (0, 20), "PLT": (0, 500),
                "Neutrophil": (0, 100), "Lymphocyte": (0, 100), "AST": (0, 100), "ALT": (0, 100),
                "BUN": (0, 50), "Cr": (0, 3), "Glucose": (0, 200), "Total_Protein": (0, 10),
                "Na": (120, 160), "K": (2, 7), "Cl": (80, 120)
            }

            # --- ì¡°ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ìˆœ ì •ë ¬ (LightGBM ê¸°ì¤€) ---
            shap_mean_lgbm = np.abs(shap_values_lgbm[:, feature_indices_lgbm]).mean(axis=0)
            feature_importance_lgbm = list(zip(filtered_features_lgbm, shap_mean_lgbm))
            sorted_features_lgbm = [
                feat for feat, val in sorted(feature_importance_lgbm, key=lambda x: x[1], reverse=True)
                if feat in blood_values and feat in normal_ranges
            ]

            # --- ì¡°ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ìˆœ ì •ë ¬ (XGBoost ê¸°ì¤€) ---
            shap_mean_xgb = np.abs(shap_values_xgb[:, feature_indices_xgb]).mean(axis=0)
            feature_importance_xgb = list(zip(filtered_features_xgb, shap_mean_xgb))
            sorted_features_xgb = [
                feat for feat, val in sorted(feature_importance_xgb, key=lambda x: x[1], reverse=True)
                if feat in blood_values and feat in normal_ranges
            ]

            # ----------------- Streamlit ì¶œë ¥ -------------------
            with st.expander(f"ğŸ“Š {texts['ë³€ìˆ˜ì¤‘ìš”ë„ ê¸°ë°˜ í™˜ì ìˆ˜ì¹˜ í™•ì¸']}"):

                # ì¢Œ/ìš° ë°•ìŠ¤ ìƒì„±
                col_lgbm, col_xgb = st.columns(2)

                with col_lgbm:
                    st.markdown(
                            f"### ğŸ”µ LightGBM {texts['ê¸°ì¤€']}&nbsp;&nbsp;&nbsp; "
                            f"<span style='font-size:12px;'><span style='color:red;'>â—</span> {texts['í™˜ììˆ˜ì¹˜']}</span>, "
                            f"<span style='font-size:12px; background-color:#a4d4a4; padding:1px 5px; border-radius:2px;'>{texts['ì •ìƒë²”ìœ„']}</span>",
                            unsafe_allow_html=True
                        )
                    lgbm_container = st.container()
                    for feature in sorted_features_lgbm:
                        value = blood_values.get(feature)
                        fig = plot_single_variable_graph(
                            feature=feature,
                            value=value,
                            normal_ranges=normal_ranges,
                            xlim_range=custom_xlims.get(feature, (0, 400)),
                            title_fontsize=8,
                            tick_fontsize=6
                        )
                        lgbm_container.pyplot(fig)

                with col_xgb:
                    st.markdown(
                        f"### ğŸŸ¢ XGBoost {texts['ê¸°ì¤€']}&nbsp;&nbsp;&nbsp; "
                        f"<span style='font-size:12px;'><span style='color:red;'>â—</span> {texts['í™˜ììˆ˜ì¹˜']}</span>, "
                        f"<span style='font-size:12px; background-color:#a4d4a4; padding:1px 5px; border-radius:2px;'>{texts['ì •ìƒë²”ìœ„']}</span>",
                        unsafe_allow_html=True
                    )
                    xgb_container = st.container()
                    for feature in sorted_features_xgb:
                        value = blood_values.get(feature)
                        fig = plot_single_variable_graph(
                            feature=feature,
                            value=value,
                            normal_ranges=normal_ranges,
                            xlim_range=custom_xlims.get(feature, (0, 400)),
                            title_fontsize=8,
                            tick_fontsize=6
                        )
                        xgb_container.pyplot(fig)

                for var, val in blood_values.items():
                    if var in normal_ranges:
                        low, high = normal_ranges[var]
                        if val < low:
                            direction = f"<span style='color:#d62728;'>{texts['ë‚®ì•„']}</span>, <b>{texts['ì¦ê°€ì‹œì¼œì•¼ í•¨.']}</b>"
                        elif val > high:
                            direction = f"<span style='color:#1f77b4;'>{texts['ë†’ì•„']}</span>, <b>{texts['ê°ì†Œì‹œì¼œì•¼ í•¨.']}</b>"
                        else:
                            continue  # ì •ìƒë²”ìœ„ ë‚´ ìˆ˜ì¹˜ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ

                        # ë³€ìˆ˜ ìˆ˜ì¹˜ í•´ì„ ë¬¸ì¥ êµ¬ì„±
                        st.markdown(
                            f"<p style='text-align: center;'>ğŸ“ <b>{var}</b> {texts['ìˆ˜ì¹˜ëŠ”']} <b>{val}</b>{texts['ë¡œ']} "
                            f"{texts['ì •ìƒë²”ìœ„ì¸']} <b>{low}~{high}</b>&nbsp;{texts['ë³´ë‹¤']} {direction}</p>",
                            unsafe_allow_html=True
                        )


            # âœ… Google Sheetsì— ë°ì´í„° ì €ì¥
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
            save_data = {
                'timestamp': timestamp,
                'language': lang_choice_label,
                'hospital': selected_hospital,
                'id': id_value,
                'birth': birth_date.strftime("%Y-%m-%d"),
                'sex': gender,
                'name': name,
                'hsptcd': hsptcd,
                'side': side,
                'hl_duration': hl_duration.strip() if hl_duration else '',
                'clinic_date': str(clinic_date),
                'steroid_treatment': int(steroid),
                'it_dexa_treatment': int(it_dexa),
                'hyperbaric_treatment': int(hbot),
                'pta_rt_ac_250': pta_values.get('PTA_RT_AC_250', ''),
                'pta_rt_ac_500': pta_values.get('PTA_RT_AC_500', ''),
                'pta_rt_ac_1000': pta_values.get('PTA_RT_AC_1000', ''),
                'pta_rt_ac_2000': pta_values.get('PTA_RT_AC_2000', ''),
                'pta_rt_ac_3000': pta_values.get('PTA_RT_AC_3000', ''),
                'pta_rt_ac_4000': pta_values.get('PTA_RT_AC_4000', ''),
                'pta_rt_ac_8000': pta_values.get('PTA_RT_AC_8000', ''),
                'pta_lt_ac_250': pta_values.get('PTA_LT_AC_250', ''),
                'pta_lt_ac_500': pta_values.get('PTA_LT_AC_500', ''),
                'pta_lt_ac_1000': pta_values.get('PTA_LT_AC_1000', ''),
                'pta_lt_ac_2000': pta_values.get('PTA_LT_AC_2000', ''),
                'pta_lt_ac_3000': pta_values.get('PTA_LT_AC_3000', ''),
                'pta_lt_ac_4000': pta_values.get('PTA_LT_AC_4000', ''),
                'pta_lt_ac_8000': pta_values.get('PTA_LT_AC_8000', ''),
                'wbc': blood_values.get('WBC', ''),
                'rbc': blood_values.get('RBC', ''),
                'hb': blood_values.get('Hb', ''),
                'plt': blood_values.get('PLT', ''),
                'neutrophil': blood_values.get('Neutrophil', ''),
                'lymphocyte': blood_values.get('Lymphocyte', ''),
                'ast': blood_values.get('AST', ''),
                'alt': blood_values.get('ALT', ''),
                'bun': blood_values.get('BUN', ''),
                'cr': blood_values.get('Cr', ''),
                'glucose': blood_values.get('Glucose', ''),
                'total_protein': blood_values.get('Total_Protein', ''),
                'na': blood_values.get('Na', ''),
                'k': blood_values.get('K', ''),
                'cl': blood_values.get('Cl', ''),
                'dx_com': diagnosis_values.get('Dx_COM', 0),
                'dx_ssnhl': diagnosis_values.get('Dx_SSNHL', 0),
                'dx_dizziness': diagnosis_values.get('Dx_Dizziness', 0),
                'dx_tinnitus': diagnosis_values.get('Dx_Tinnitus', 0),
                'hx_htn': history_values.get('Hx_HTN', 0),
                'hx_dm': history_values.get('Hx_DM', 0),
                'hx_crf': history_values.get('Hx_CRF', 0),
                'hx_mi': history_values.get('Hx_MI', 0),
                'hx_stroke': history_values.get('Hx_stroke', 0),
                'hx_cancer': history_values.get('Hx_cancer', 0),
                'hx_others': hx_others_text,
                'prediction': f"LightGBM: {lgbm_prob[0]*100:.1f}%, XGBoost: {xgb_prob[0]*100:.1f}%",
                'probability': f"LightGBM: {'íšŒë³µ' if lgbm_prob[0] >= 0.5 else 'ë¹„íšŒë³µ'}, XGBoost: {'íšŒë³µ' if xgb_prob[0] >= 0.5 else 'ë¹„íšŒë³µ'}"
            }
            
            # Google Sheetsì— ì €ì¥ (ì¡°ìš©íˆ ì‹¤í–‰)
            save_to_sheets(save_data)

            # ê²°ê³¼ ì •ë¦¬ í…ìŠ¤íŠ¸
            summary_lgbm = f"íšŒë³µ í™•ë¥  {lgbm_prob_val:.1f}%, ì˜ˆì¸¡ì •í™•ë„ {predictor.lgbm_acc * 100:.1f}%."
            summary_xgb = f"íšŒë³µ í™•ë¥  {xgb_prob_val:.1f}%, ì˜ˆì¸¡ì •í™•ë„ {predictor.xgb_acc * 100:.1f}%."

            # ğŸ“¸ ê²°ê³¼ ìš”ì•½ ì´ë¯¸ì§€ ìƒì„±
            def create_summary_image(
                name,
                hospital,
                clinic_date,
                summary_lgbm,
                summary_xgb,
                fig_lgbm,
                fig_xgb,
                font_path=None  # í°íŠ¸ ê²½ë¡œë¥¼ Noneìœ¼ë¡œ ì„¤ì •
            ):
                # A4 ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì„¤ì • (ë‹¨ìœ„: í”½ì…€)
                a4_width, a4_height = 595, 842  # 72dpi ê¸°ì¤€ A4: 595 x 842
                margin = 40
                gap = 30
                table_height = 120
                text_height = 80
                graph_width = (a4_width - margin * 2 - gap) // 2

                # SHAP ê·¸ë˜í”„ ì €ì¥ ë° ë¦¬ì‚¬ì´ì§•
                buf_lgbm, buf_xgb = io.BytesIO(), io.BytesIO()
                fig_lgbm.savefig(buf_lgbm, format='png', bbox_inches='tight')
                fig_xgb.savefig(buf_xgb, format='png', bbox_inches='tight')
                buf_lgbm.seek(0)
                buf_xgb.seek(0)
                img_lgbm = Image.open(buf_lgbm)
                img_xgb = Image.open(buf_xgb)

                # ê·¸ë˜í”„ í¬ê¸° ì¡°ì •
                img_lgbm = img_lgbm.resize((graph_width, int(graph_width * img_lgbm.height / img_lgbm.width)))
                img_xgb = img_xgb.resize((graph_width, int(graph_width * img_xgb.height / img_xgb.width)))
                graph_height = max(img_lgbm.height, img_xgb.height)

                # ì „ì²´ ì´ë¯¸ì§€ ìº”ë²„ìŠ¤ ìƒì„±
                total_height = margin + 30 + table_height + text_height + graph_height + margin
                img = Image.new("RGB", (a4_width, a4_height), (255, 255, 255))
                draw = ImageDraw.Draw(img)

                # í°íŠ¸ ì„¤ì • - ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© ë˜ëŠ” ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„
                try:
                    # Windows í™˜ê²½ì¸ ê²½ìš° ë§‘ì€ ê³ ë”• ì‹œë„
                    if os.name == 'nt' and os.path.exists("C:/Windows/Fonts/malgun.ttf"):
                        font_title = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", 30)
                        font_main = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", 15)
                        font_bold = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", 15)
                    else:
                        # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                        font_title = ImageFont.load_default()
                        font_main = ImageFont.load_default()
                        font_bold = ImageFont.load_default()
                except:
                    # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                    font_title = ImageFont.load_default()
                    font_main = ImageFont.load_default()
                    font_bold = ImageFont.load_default()

                # ì œëª© ì¶œë ¥
                title = "SSNHL ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½"
                try:
                    title_width = draw.textlength(title, font=font_title)
                except:
                    title_width = len(title) * 10  # ëŒ€ëµì ì¸ ê³„ì‚°
                draw.text(((a4_width - title_width) // 2, margin), title, fill=(0, 0, 0), font=font_title)

                # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
                base_y = margin + 80
                info_lines = [
                    f"ì˜ˆì¸¡ì¼ì: {clinic_date}",
                    f"ë³‘ì›ëª…: {hospital}",
                    f"í™˜ìëª…: {name}",
                ]
                for i, line in enumerate(info_lines):
                    draw.text((margin, base_y + i * 20), line, fill=(0, 0, 0), font=font_main)

                # ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ í…ìŠ¤íŠ¸ ì¶œë ¥
                result_y = base_y + 1 * 10 + 200
                result_texts = [
                    f"ğŸ”µ LightGBM ê¸°ì¤€ : {summary_lgbm}",
                    f"ğŸŸ¢ XGBoost ê¸°ì¤€ : {summary_xgb}"
                ]
                for i, line in enumerate(result_texts):
                    try:
                        text_width = draw.textlength(line, font=font_main)
                    except:
                        text_width = len(line) * 8
                    draw.text(((a4_width - text_width) // 2, result_y + i * 22), line, fill=(0, 0, 0), font=font_main)

                # SHAP ê·¸ë˜í”„ ì‚½ì…
                graph_y = result_y + len(result_texts) * 22 + 50
                img.paste(img_lgbm, (margin, graph_y))
                img.paste(img_xgb, (margin + graph_width + gap, graph_y))

                # ê·¸ë˜í”„ ì•„ë˜ ëª¨ë¸ëª… ë¼ë²¨ ì¶œë ¥
                draw.text((margin + graph_width // 2 - 70, graph_y - 20), "ğŸ” LightGBM ë³€ìˆ˜ ì¤‘ìš”ë„", font=font_bold, fill=(0, 0, 0))
                draw.text((margin + graph_width + gap + graph_width // 2 - 70, graph_y - 20), "ğŸ” XGBoost ë³€ìˆ˜ ì¤‘ìš”ë„", font=font_bold, fill=(0, 0, 0))

                # ì´ë¯¸ì§€ ë°˜í™˜ (BytesIO í˜•íƒœë¡œ ë°˜í™˜)
                result_buf = io.BytesIO()
                img.save(result_buf, format="PNG")
                result_buf.seek(0)
                return result_buf

            # ì´ë¯¸ì§€ ìƒì„±
            img_buf = create_summary_image(
                name=name,
                hospital=selected_hospital,
                clinic_date=clinic_date,
                summary_lgbm=summary_lgbm,
                summary_xgb=summary_xgb,
                fig_lgbm=fig_lgbm,
                fig_xgb=fig_xgb
            )

            def convert_image_to_pdf(image_bytes):
                buffer = io.BytesIO()
                c = canvas.Canvas(buffer, pagesize=A4)
                width, height = A4
                image = ImageReader(image_bytes)
                c.drawImage(image, 0, 0, width=width, height=height)
                c.showPage()
                c.save()
                buffer.seek(0)
                return buffer
            
            pdf_buf = convert_image_to_pdf(img_buf)

            # ğŸ”½ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            col_result, col_button = st.columns([5, 1])

            with col_button:
                with st.expander("ğŸ’¾"+texts["ê²°ê³¼ ì €ì¥"], expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button("ğŸ–¼ PNG"+texts["ì €ì¥"], data=img_buf, file_name="result.png", mime="image/png")
                    with col2:
                        st.download_button("ğŸ“„ PDF"+ texts["ì €ì¥"], data=pdf_buf, file_name="result.pdf", mime="application/pdf")
